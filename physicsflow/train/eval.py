"""
Detailed evaluation of the model, its predictions, and the losses.
By: Florian Wiesner
Date: 2025-05-01
"""

from pathlib import Path
from typing import Optional
import logging
import math

import torch
from torch.utils.data import DataLoader
import torch.distributed as dist

from physicsflow.models.flow_matching.flow_matching_model import FlowMatchingOutput
from physicsflow.train.utils.run_utils import compute_metrics, reduce_all_losses
from physicsflow.train.utils.logger import setup_logger


class Evaluator:
    """Thorough evaluation of the model on the full dataset.

    Parameters
    ----------
    model : torch.nn.Module
        The model to evaluate
    dataloader : DataLoader
        Dataloader to evaluate on
    metrics : dict[str, torch.nn.Module]
        Dictionary of metrics to evaluate
    eval_dir : Path
        Directory to save evaluation results
    eval_fraction : float, optional
        Fraction of validation data to use for evaluation (0, 1], by default 1.0
    amp : bool, optional
        Whether to use automatic mixed precision, by default True
    amp_precision : torch.dtype, optional
        Precision to use for AMP, by default torch.bfloat16
    global_rank : int, optional
        Global rank for distributed training, by default 0
    local_rank : int, optional
        Local rank for distributed training, by default 0
    world_size : int, optional
        World size for distributed training, by default 1
    logger : logging.Logger, optional
        Logger to use, by default None
    """

    def __init__(
        self,
        model: torch.nn.Module,
        dataloader: DataLoader,
        metrics: dict[str, torch.nn.Module],
        eval_dir: Path,
        eval_fraction: float = 1.0,
        amp: bool = True,
        amp_precision: torch.dtype = torch.bfloat16,
        global_rank: int = 0,
        local_rank: int = 0,
        world_size: int = 1,
        logger: Optional[logging.Logger] = None,
    ):
        self.logger = logger or setup_logger("Evaluator", rank=global_rank)
        self.global_rank = global_rank
        if not (0.0 < eval_fraction <= 1.0):
            raise ValueError(
                f"eval_fraction must be in the range (0, 1], got {eval_fraction}."
            )
        self.eval_fraction = eval_fraction
        self.local_rank = local_rank
        self.world_size = world_size
        self.device = (
            torch.device(f"cuda:{self.local_rank}")
            if torch.cuda.is_available()
            else torch.device("cpu")
        )
        self.ddp_enabled = dist.is_initialized()

        self.model = model
        self.model.eval()
        self.model.to(self.device)

        self.dataloader = dataloader
        self.metrics = metrics
        self.eval_dir = eval_dir
        self.eval_dir.mkdir(parents=True, exist_ok=True)

        self.use_amp = amp
        self.amp_precision = amp_precision

    def log_msg(self, msg: str):
        """Log a message."""
        self.logger.info(f"{msg}")

    @torch.inference_mode()
    def eval(self) -> dict[str, torch.Tensor]:
        """Evaluate the model on the full dataset.

        Returns
        -------
        dict[str, torch.Tensor]
            Dictionary of metrics (losses) averaged over the full dataset.
        """
        total_metrics = {}
        for metric_name, _ in self.metrics.items():
            total_metrics[metric_name] = torch.tensor(0.0, device=self.device)

        n_total_batches = len(self.dataloader)
        if n_total_batches == 0:
            raise ValueError("Validation dataloader is empty.")
        n_batches = min(
            n_total_batches,
            max(1, math.ceil(n_total_batches * self.eval_fraction)),
        )
        log_interval = max(1, 10 ** math.floor(math.log10(max(1, n_batches // 100))))
        model_input_dtype = next(self.model.parameters()).dtype

        for i, data in enumerate(self.dataloader):
            if (i + 1) % log_interval == 0 or i == 0:
                self.log_msg(f"Batch {i + 1}/{n_batches}")

            # Move all tensors in dict to device
            data = {
                k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                for k, v in data.items()
            }
            t1 = data["output_fields"]
            cond = data["constant_scalars"]
            if t1.is_floating_point():
                t1 = t1.to(dtype=model_input_dtype)
            if cond is not None and cond.is_floating_point():
                cond = cond.to(dtype=model_input_dtype)

            with torch.autocast(
                device_type=self.device.type,
                dtype=self.amp_precision,
                enabled=self.use_amp,
            ):
                output: FlowMatchingOutput = self.model(t1, cond)

            current_metrics = compute_metrics(
                output.predicted_velocity, output.target_velocity, self.metrics
            )

            current_metrics = reduce_all_losses(current_metrics)
            for metric_name, metric_value in current_metrics.items():
                total_metrics[metric_name] += metric_value.float()

            if i + 1 >= n_batches:
                break

        for metric_name, metric_value in total_metrics.items():
            total_metrics[metric_name] /= n_batches

        return total_metrics
